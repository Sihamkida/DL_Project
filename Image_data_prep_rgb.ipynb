{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data as Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(os.path.abspath(\"/home/monty/Desktop/DL Project/DeepLearning_group_2/mros-data-main/mros_data\")))\n",
    "from mros_data.datamodule import SleepEventDataModule\n",
    "from mros_data.datamodule.transforms import STFTTransform\n",
    "from matplotlib import patches\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method to convert spectograms into Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectogram_to_image(signals):\n",
    "\n",
    "    ch_mix = abs(signals[0] - signals[1])\n",
    "    signals = np.append(signals, [ch_mix], axis=0)\n",
    "\n",
    "    spectrogram = np.dstack([signals[0],signals[1],signals[2]])\n",
    "\n",
    "    tensor= torch.tensor(spectrogram)*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "\n",
    "    return Image.fromarray((tensor).astype(np.uint8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and using this method we make folder with eval and train set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveImagesToFolder(train_ds,eval_ds):\n",
    "    len_train = len(train_ds)\n",
    "    len_eval = len(eval_ds)\n",
    "\n",
    "    img_path = \"/home/monty/Desktop/DL Project/DeepLearning_group_2/coco5\"\n",
    "\n",
    "    if os.path.isdir(img_path) == False:\n",
    "        os.mkdir(img_path)\n",
    "        os.mkdir(f\"{img_path}/train\")\n",
    "        os.mkdir(f\"{img_path}/eval\")\n",
    "        os.mkdir(f\"{img_path}/annotations\")\n",
    "\n",
    "    for x in range(len_train):\n",
    "        img = spectogram_to_image(train_ds[x][\"signal\"])\n",
    "\n",
    "        img_name = f\"train_{x}.png\"\n",
    "        image = img.save(f\"{img_path}/train/{img_name}\")\n",
    "\n",
    "    for x in range(len_eval):\n",
    "        img = spectogram_to_image(eval_ds[x][\"signal\"])\n",
    "\n",
    "        img_name = f\"eval_{x}.png\"\n",
    "        image = img.save(f\"{img_path}/eval/{img_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    data_dir=\"/home/monty/Desktop/DL Project/DeepLearning_group_2/lm/\",\n",
    "    batch_size=16,\n",
    "    n_eval=2,\n",
    "    n_test=2,\n",
    "    num_workers=0,\n",
    "    seed=1337,\n",
    "    events={\"lm\": \"Leg movement\"},\n",
    "    window_duration=600,  # seconds\n",
    "    cache_data=True,\n",
    "    default_event_window_duration=[15],\n",
    "    event_buffer_duration=3,\n",
    "    factor_overlap=2,\n",
    "    fs=64,\n",
    "    matching_overlap=0.5,\n",
    "    n_jobs=-1,\n",
    "    n_records=10,\n",
    "    picks=[\"legl\", \"legr\"],\n",
    "    # transform=MultitaperTransform(128, 0.5, 35.0, tw=8.0, normalize=True),\n",
    "    transform=STFTTransform(\n",
    "        fs=64, segment_size=int(4.0 * 64), step_size=int(0.125 * 64), nfft=1024, normalize=True\n",
    "    ),\n",
    "    scaling=\"robust\",\n",
    ")\n",
    "dm = SleepEventDataModule(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup('fit')\n",
    "train_ds = dm.train\n",
    "eval_ds = dm.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a signal to spectogram image\n",
    "\n",
    "data_loader_train = dm.train_dataloader()\n",
    "data_loader_val = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = train_ds.get_2Dmatrix(0, channel_idx=0, window_size=int(4.0 * train_ds.fs), step_size=int(0.125 * train_ds.fs), nfft=1024)\n",
    "IMG = spectogram_to_image(spectrogram)\n",
    "imgplot = plt.imshow(IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG2 = spectogram_to_image(train_ds[0][\"signal\"])\n",
    "\n",
    "imgplot2 = plt.imshow(IMG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating the image folders and files\n",
    "\n",
    "SaveImagesToFolder(train_ds,eval_ds)\n",
    "\n",
    "def PlotImageWithBoxes(image,events):\n",
    "    _events = np.delete(events, 2, 1)*image.width\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(len(_events)):\n",
    "        x = _events[i,1]\n",
    "        y = 0\n",
    "        width = _events[i,1] - _events[i,0]\n",
    "        height = IMG.height\n",
    "        bbox = (x, y, width, height)\n",
    "        bb = patches.Rectangle((bbox[0],bbox[1]), bbox[2],bbox[3], linewidth=1, edgecolor=\"green\", facecolor=\"none\")\n",
    "        ax.add_patch(bb)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us create the annotation file\n",
    "\n",
    "def AddAnnotations(res_file,Start,End,Height,annot_count,image_id):\n",
    "    xmin = Start\n",
    "    ymin = 0\n",
    "    xmax = End\n",
    "    ymax = Height\n",
    "    w = End-Start\n",
    "    h = Height\n",
    "    area = w * h\n",
    "    poly = [[xmin, ymin],\n",
    "            [xmax, ymin],\n",
    "            [xmax, ymax],\n",
    "            [xmin, ymax]]\n",
    "\n",
    "    annot_elem = {\n",
    "        \"id\": annot_count,\n",
    "        \"bbox\": [\n",
    "            float(xmin),\n",
    "            float(ymin),\n",
    "            float(w),\n",
    "            float(h)\n",
    "        ],\n",
    "        \"segmentation\": list([poly]),\n",
    "        \"image_id\": image_id,\n",
    "        \"ignore\": 0,\n",
    "        \"category_id\": 0,\n",
    "        \"iscrowd\": 0,\n",
    "        \"area\": float(area)\n",
    "    }\n",
    "    res_file[\"annotations\"].append(annot_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddImage(res_file,img,events,annot_count, image_id,isTrain):\n",
    "\n",
    "    if isTrain:\n",
    "        path = f\"/content/gdrive/MyDrive/coco5/train/train_{image_id}.png\"\n",
    "    else:\n",
    "        path = f\"/content/gdrive/MyDrive/coco5/eval/eval_{image_id}.png\"\n",
    "\n",
    "    img_w, img_h = img.size\n",
    "    img_elem = {\"file_name\": f\"{path}\",\n",
    "                \"height\": img_h,\n",
    "                \"width\": img_w,\n",
    "                \"id\": image_id}\n",
    "    for elm in range(len(events)):\n",
    "        AddAnnotations(res_file,float(events[elm,0]),float(events[elm,1]),img_h,annot_count,image_id)\n",
    "        annot_count += 1\n",
    "    res_file[\"images\"].append(img_elem)\n",
    "    return annot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateAnnotationFile(train_ds,eval_ds):\n",
    "    len_train = len(train_ds)\n",
    "    len_eval = len(eval_ds)\n",
    "\n",
    "    json_path = \"/home/monty/Desktop/DL Project/DeepLearning_group_2/coco5/annotations\"\n",
    "\n",
    "    categories = [\n",
    "    {\n",
    "        \"supercategory\": \"none\",\n",
    "        \"name\": \"movement\",\n",
    "        \"id\": 0\n",
    "    }]\n",
    "\n",
    "    res_file = {\n",
    "        \"categories\": categories,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    annot_count = 0\n",
    "    image_id = 0\n",
    "    json_file = \"instances_train2017.json\"\n",
    "\n",
    "    for x in range(len_train):\n",
    "        spectrogram = train_ds.get_2Dmatrix(x, channel_idx=0, window_size=int(4.0 * train_ds.fs),\n",
    "                                            step_size=int(0.125 * train_ds.fs), nfft=1024)\n",
    "        img = spectogram_to_image(spectrogram)\n",
    "        events = train_ds[x]['events']\n",
    "        annot_count = AddImage(res_file,img,events,annot_count, image_id,True)\n",
    "        image_id += 1\n",
    "        #print(\"\\tProcessed {}/{} images.\".format(image_id,len_train))\n",
    "\n",
    "    with open(os.path.join(json_path,json_file), \"w\") as f:\n",
    "        json_str = json.dumps(res_file)\n",
    "        f.write(json_str)\n",
    "\n",
    "    print(\"Processed {} train images...\".format(image_id))\n",
    "\n",
    "    categories = [\n",
    "    {\n",
    "        \"supercategory\": \"none\",\n",
    "        \"name\": \"movement\",\n",
    "        \"id\": 0\n",
    "    }]\n",
    "\n",
    "    res_file = {\n",
    "        \"categories\": categories,\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    annot_count = 0\n",
    "    image_id = 0\n",
    "    json_file = \"instances_val2017.json\"\n",
    "\n",
    "    for x in range(len_eval):\n",
    "        spectrogram = eval_ds.get_2Dmatrix(x, channel_idx=0, window_size=int(4.0 * train_ds.fs),\n",
    "                                            step_size=int(0.125 * train_ds.fs), nfft=1024)\n",
    "        img = spectogram_to_image(spectrogram)\n",
    "        events = train_ds[x]['events']\n",
    "        annot_count = AddImage(res_file,img,events,annot_count, image_id,False)\n",
    "        image_id += 1\n",
    "        #print(\"\\tProcessed {}/{} images.\".format(image_id,len_eval))\n",
    "\n",
    "    with open(os.path.join(json_path,json_file), \"w\") as f:\n",
    "        json_str = json.dumps(res_file)\n",
    "        f.write(json_str)\n",
    "    print(\"Processed {} eval images...\".format(image_id))\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateAnnotationFile(train_ds,eval_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DLVC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d05d5406fd9e65b8cec1a934232fb9faf3a0fca3877bdfa444f1bd6416e14e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
